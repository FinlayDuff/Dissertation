{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "780197cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/finlayduff/Documents/BATH MSc/Dissertation\")\n",
    "from utils.data.results import load_combined_results\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "262a7b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"recovery-news-data_None\"\n",
    "experiment_id = \"eca18c07-5a96-44a7-94d9-e8ef59644c33\"\n",
    "df = load_combined_results(dataset_name=dataset_name, experiment_id=experiment_id)\n",
    "df = df.join(pd.json_normalize(df['captured_credibility_signals']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f3a908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "###############################################################################\n",
    "# 1.  Condensed credibility‑signal definitions\n",
    "###############################################################################\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Signal:\n",
    "    \"\"\"Metadata for a signal extracted by the LLM.\"\"\"\n",
    "    name: str\n",
    "    risk: bool  # True if presence indicates *lower* credibility\n",
    "\n",
    "\n",
    "SIGNALS: List[Signal] = [\n",
    "    # factual‑evidence signals (presence = good)\n",
    "    Signal(\"evidence_present\", False),\n",
    "    Signal(\"explicit_unverified_claim\", True),\n",
    "    Signal(\"inference_error\", True),\n",
    "\n",
    "    # source‑quality signals\n",
    "    Signal(\"credible_sourcing\", False),\n",
    "    Signal(\"external_corroboration\", False),\n",
    "\n",
    "    # style / tone risk signals\n",
    "    Signal(\"strong_framing_tone\", True),\n",
    "    Signal(\"clickbait_headline\", True),\n",
    "    Signal(\"writing_quality_alert\", True),\n",
    "]\n",
    "\n",
    "SIGNAL_INDEX: Dict[str, int] = {s.name: i for i, s in enumerate(SIGNALS)}\n",
    "FEATURE_DIM: int = len(SIGNALS)\n",
    "\n",
    "###############################################################################\n",
    "# 2.  Vectorisation helpers\n",
    "###############################################################################\n",
    "\n",
    "SignalResult = Tuple[bool, float]  # (label_is_true, confidence)\n",
    "SignalDict = Dict[str, SignalResult]\n",
    "\n",
    "\n",
    "def signals_to_features(sig_dict: SignalDict) -> np.ndarray:\n",
    "    \"\"\"Convert a *single* article's signals into a feature vector (1 x d).\"\"\"\n",
    "    vec = np.zeros(FEATURE_DIM, dtype=np.float32)\n",
    "    for name, (is_true, conf) in sig_dict.items():\n",
    "        idx = SIGNAL_INDEX.get(name)\n",
    "        if idx is None:\n",
    "            continue  # ignore unknown signals\n",
    "        polarity = -1 if SIGNALS[idx].risk else 1  # invert risk signals\n",
    "        vec[idx] = polarity * conf if is_true else 0.0\n",
    "    return vec\n",
    "\n",
    "\n",
    "def batch_to_matrix(batch: List[SignalDict]) -> np.ndarray:\n",
    "    \"\"\"Stack many article‑level dicts into an (n x d) matrix.\"\"\"\n",
    "    return np.vstack([signals_to_features(b) for b in batch])\n",
    "\n",
    "def dataframe_to_matrix(df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Convert a pandas DataFrame with Boolean columns into (n x d) matrix.\"\"\"\n",
    "    arr = np.zeros((len(df), FEATURE_DIM), dtype=np.float32)\n",
    "    for sig in SIGNALS:\n",
    "        if sig.name in df.columns:\n",
    "            values = df[sig.name].astype(float).to_numpy()\n",
    "            polarity = -1 if sig.risk else 1\n",
    "            arr[:, SIGNAL_INDEX[sig.name]] = polarity * values\n",
    "    return arr\n",
    "\n",
    "###############################################################################\n",
    "# 3.  Model helpers\n",
    "###############################################################################\n",
    "\n",
    "def _make_calibrator(base: LogisticRegression) -> CalibratedClassifierCV:\n",
    "    \"\"\"Return a calibrated classifier compatible with any sklearn version.\"\"\"\n",
    "    try:\n",
    "        # sklearn ≥ 1.1 (base_estimator removed in 1.3)\n",
    "        return CalibratedClassifierCV(estimator=base, method=\"sigmoid\", cv=5)\n",
    "    except TypeError:\n",
    "        # fallback for older versions\n",
    "        return CalibratedClassifierCV(base_estimator=base, method=\"sigmoid\", cv=5)\n",
    "\n",
    "\n",
    "def build_classifier() -> CalibratedClassifierCV:\n",
    "    base = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "    return _make_calibrator(base)\n",
    "\n",
    "\n",
    "def fit_classifier(X: np.ndarray, y: np.ndarray) -> CalibratedClassifierCV:\n",
    "    clf = build_classifier()\n",
    "    clf.fit(X, y)\n",
    "    return clf\n",
    "\n",
    "\n",
    "def fit_classifier_from_dataframe(X_df: pd.DataFrame, y_series: pd.Series) -> CalibratedClassifierCV:\n",
    "    X_mat = dataframe_to_matrix(X_df)\n",
    "    return fit_classifier(X_mat, y_series.to_numpy())\n",
    "\n",
    "\n",
    "def predict_proba(clf: CalibratedClassifierCV, sig_dict: SignalDict) -> float:\n",
    "    X = signals_to_features(sig_dict).reshape(1, -1)\n",
    "    return float(clf.predict_proba(X)[0, 1])\n",
    "\n",
    "\n",
    "def predict_proba_df(clf: CalibratedClassifierCV, row: pd.Series) -> float:\n",
    "    X = dataframe_to_matrix(row.to_frame().T)\n",
    "    return float(clf.predict_proba(X)[0, 1])\n",
    "\n",
    "\n",
    "def save_model(clf: CalibratedClassifierCV, path: str | Path) -> None:\n",
    "    joblib.dump(clf, Path(path))\n",
    "\n",
    "\n",
    "def load_model(path: str | Path) -> CalibratedClassifierCV:\n",
    "    return joblib.load(Path(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2951201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.signals import CREDIBILITY_SIGNALS_CONDENSED\n",
    "training_columns = CREDIBILITY_SIGNALS_CONDENSED.keys()\n",
    "feature_columns = [f\"{col}.label\" for col in training_columns]\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[\"actual\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08a5859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = fit_classifier_from_dataframe(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5eab3f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(dataframe_to_matrix(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b86859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.000     0.000     0.000       132\n",
      "           1      0.672     1.000     0.804       271\n",
      "\n",
      "    accuracy                          0.672       403\n",
      "   macro avg      0.336     0.500     0.402       403\n",
      "weighted avg      0.452     0.672     0.541       403\n",
      "\n",
      "Confusion matrix:\n",
      " [[  0 132]\n",
      " [  0 271]]\n",
      "ROC AUC : 0.5\n",
      "Brier   : 0.22025984708492638\n",
      "PR  AUC : 0.8362282878411911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/finlayduff/.pyenv/versions/3.10.4/envs/fakenews_venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/finlayduff/.pyenv/versions/3.10.4/envs/fakenews_venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/finlayduff/.pyenv/versions/3.10.4/envs/fakenews_venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score,\n",
    "    brier_score_loss, precision_recall_curve, auc\n",
    ")\n",
    "\n",
    "# if you did a train/test split\n",
    "y_score = clf.predict_proba(dataframe_to_matrix(X_test))[:, 1]\n",
    "y_pred  = (y_score >= 0.5).astype(int)          # default 0.5 threshold\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"ROC AUC :\", roc_auc_score(y_test, y_score))\n",
    "print(\"Brier   :\", brier_score_loss(y_test, y_score))\n",
    "\n",
    "# Precision–recall AUC (often more informative if the classes are imbalanced)\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_score)\n",
    "print(\"PR  AUC :\", auc(rec, prec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf51623",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733fd086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakenews_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

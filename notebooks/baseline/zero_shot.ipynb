{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries and set the paths\n",
    "import sys\n",
    "import os\n",
    "notebook_dir = os.getcwd()\n",
    "root = os.path.abspath(os.path.join(notebook_dir, '../../'))\n",
    "sys.path.append(root)\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from utils.data.csv_parsing import load_csv_as_dicts, load_csv_as_dataframe\n",
    "from utils.langchain.llm_model_selector import get_llm_from_model_name\n",
    "from utils.langchain.prompts import STRUCTURED_OUTPUT_PROMPT, NAIVE_ZERO_SHOT_CLASSIFICATION_PROMPT, ROBUST_ZERO_SHOT_CLASSIFICATION_PROMPT\n",
    "\n",
    "import getpass\n",
    "from pydantic import BaseModel\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langsmith.evaluation import evaluate\n",
    "from langsmith.schemas import Example, Run\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_path = '/data/transformed/FA-KES.csv'\n",
    "\n",
    "articles = load_csv_as_dicts(root+article_path)\n",
    "articles_df = load_csv_as_dataframe(root+article_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"FakeNews Detection - Zero Shot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "# Utility function to get the right model\n",
    "def get_llm_from_model_name(model_name: str):\n",
    "    if \"claude\" in model_name:\n",
    "        return ChatAnthropic(model=model_name,temperature=0)\n",
    "    elif \"gpt\" in model_name:\n",
    "        return ChatOpenAI(model=model_name,temperature=0)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model provider for model: {model_name}\")\n",
    "\n",
    "# Define the state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, \"A list to store messages exchanged with the LLM\"]\n",
    "    article_title: Annotated[str, \"The title of the article to be analysed\"]\n",
    "    article_content: Annotated[str, \"The content of the article to be analysed\"]\n",
    "    label: Annotated[str, \"The label of the classification ('Credible' or 'Fake')\"]\n",
    "    explanation: Annotated[str, \"The reasoning behind the classification\"]\n",
    "\n",
    "# Class for misinformation detection workflow\n",
    "class MisinformationDetection:\n",
    "    def __init__(self, model_name: str, system_message_prefix: str):\n",
    "        self.llm = get_llm_from_model_name(model_name)\n",
    "        self.system_message = f\"\"\"\n",
    "            {system_message_prefix}\\n\n",
    "            {STRUCTURED_OUTPUT_PROMPT}\n",
    "        \"\"\"\n",
    "\n",
    "    def detect_misinformation(self, state: State):\n",
    "        article_title = state[\"article_title\"]\n",
    "        article_content = state[\"article_content\"]\n",
    "        input_text = f\"Title: {article_title}\\n\\nContent: {article_content}\"\n",
    "\n",
    "        response = self.llm.invoke([{\"role\": \"system\", \"content\": self.system_message}, \n",
    "                                    {\"role\": \"user\", \"content\": input_text}])\n",
    "\n",
    "        state[\"messages\"] = [response]  # Update state with response\n",
    "        return state\n",
    "\n",
    "    def handle_structured_output(self, state: State):\n",
    "        raw_output = state[\"messages\"][-1].content\n",
    "        label_start = raw_output.find(\"Label: \") + len(\"Label: \")\n",
    "        label_end = raw_output.find(\"\\n\", label_start)\n",
    "        label = raw_output[label_start:label_end].strip()\n",
    "\n",
    "        explanation_start = raw_output.find(\"Explanation:\") + len(\"Explanation:\")\n",
    "        explanation = raw_output[explanation_start:].strip()\n",
    "\n",
    "        state[\"label\"] = label\n",
    "        state[\"explanation\"] = explanation if explanation else \"No explanation provided.\"\n",
    "        return state\n",
    "\n",
    "# Class to manage the graph\n",
    "class GraphManager:\n",
    "    def __init__(self, model_name: str, system_message_prefix: str):\n",
    "        self.detection_system = MisinformationDetection(model_name,system_message_prefix)\n",
    "        self.graph_builder = StateGraph(State)\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_graph(self):\n",
    "        self.graph_builder.add_node(\"detect_fake_news\", self.detection_system.detect_misinformation)\n",
    "        self.graph_builder.add_node(\"handle_output\", self.detection_system.handle_structured_output)\n",
    "        self.graph_builder.add_edge(START, \"detect_fake_news\")\n",
    "        self.graph_builder.add_edge(\"detect_fake_news\", \"handle_output\")\n",
    "        self.graph_builder.add_edge(\"handle_output\", END)\n",
    "        self.graph = self.graph_builder.compile()\n",
    "\n",
    "    def run_graph_on_example(self, example: dict):\n",
    "        initial_state = {\n",
    "            \"messages\": [],\n",
    "            \"article_title\": example.get(\"article_title\"),\n",
    "            \"article_content\": example.get(\"article_content\")\n",
    "        }\n",
    "        final_state = self.graph.invoke(initial_state)\n",
    "        return {\n",
    "            \"label\": final_state.get(\"label\"),\n",
    "            \"explanation\": final_state.get(\"explanation\")\n",
    "        }\n",
    "\n",
    "# Class for running evaluation\n",
    "class Evaluator:\n",
    "    @staticmethod\n",
    "    def correct_label(root_run: Run, example: dict) -> dict:\n",
    "        predicted_label = root_run.outputs.get(\"label\")\n",
    "        actual_label = example.outputs.get(\"label\")\n",
    "        score = predicted_label == actual_label\n",
    "        return {\"score\": int(score), \"key\": \"correct_label\"}\n",
    "\n",
    "    @staticmethod\n",
    "    def run_evaluation(graph_manager: GraphManager, dataset_name: str):\n",
    "        results = evaluate(\n",
    "            graph_manager.run_graph_on_example,\n",
    "            data=dataset_name,\n",
    "            evaluators=[Evaluator.correct_label],\n",
    "            experiment_prefix=f\"{graph_manager.detection_system.llm.__class__.__name__}\",\n",
    "            description=\"Evaluating graph-based misinformation detection system.\"\n",
    "        )\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'ChatAnthropic-25759c41' at:\n",
      "https://smith.langchain.com/o/7ade50a2-3a1f-5106-9003-6a8cfb7b3652/datasets/a26430d4-620e-4f8b-aa7e-3676c5486d8c/compare?selectedSessions=f358ee24-6d48-401d-9f15-6ef39c371649\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:03,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ExperimentResults ChatAnthropic-25759c41>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"claude-3-haiku-20240307\"\n",
    "graph_manager = GraphManager(model_name,system_message_prefix=NAIVE_ZERO_SHOT_CLASSIFICATION_PROMPT)\n",
    "dataset_name = \"FA-KES test\"\n",
    "evaluation_results = Evaluator.run_evaluation(graph_manager, dataset_name)\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
